# GLM 标签缩放 (Label Scaling) 通用指南

**版本**: 1.1
**适用场景**: 线性回归 (Linear), 逻辑回归 (Logistic), 车险定价 (Tweedie/Gamma/Poisson)
**涉及技术**: GLM, Link Functions (Identity, Logit, Log), MPC (Secure Multi-Party Computation)

---

## 1. 核心结论速查 (Executive Summary)

在 MPC 定点数环境下，为了防止数值溢出，对目标变量 $y$ 进行缩放 ($y' = y / K$) 的影响因 **链接函数 (Link Function)** 而异：

| 模型类型 | Link Function | 典型分布 | 结论 | 建议 | 
| :--- | :--- | :--- | :--- | :--- | 
| **车险/计数回归** | **Log** | Tweedie, Gamma, Poisson | **推荐**。仅截距平移，**风险因子(斜率)完全不变**。 | $y' = y/K$。预测结果乘 $K$ 恢复。 |
| **线性回归** | **Identity** | Gaussian (Normal) | **可行**。所有系数(截距+斜率)同比例缩小。 | $y' = y/K$。需注意正则化参数 $\lambda$ 需同步调整。 |
| **逻辑回归** | **Logit** | Bernoulli, Binomial | **不推荐**。标签通常为 {0,1}，无需缩放。 | **不要缩放**。缩放会破坏 Sigmoid 函数的 [0,1] 概率假设。 |

---

## 2. 场景一：Log Link (车险定价/非负回归)

**场景**: 预测赔款金额、出险频率、点击量等非负数据。
**模型**: $\ln(\mu) = \beta_0 + \beta_1 x_1 + \dots$

### 2.1 缩放影响分析
令 $y' = y/K$。
$$ \ln(\mu') = \ln(\mu/K) = \ln(\mu) - \ln(K) $$
$$ \ln(\mu') = (\beta_0 - \ln(K)) + \beta_1 x_1 + \dots $$

*   **截距 ($\\beta_0$)**: 发生平移 $\\beta'_0 = \beta_0 - \ln(K)$。
*   **斜率 ($\\beta_{i>0}$)**: **完全不变**。
*   **风险因子 ($e^{\\beta_i}$)**: **完全不变**。

### 2.2 实施建议
*   **操作**: 训练前除以 $K$。
*   **恢复**: 最终预测结果（或基准费率）乘以 $K$。
*   **正则化**: 通常**不需要**调整 L2 正则化参数。

---

## 3. 场景二：Identity Link (线性回归)

**场景**: 房价预测、温度预测等普通连续值回归。
**模型**: $\mu = \beta_0 + \beta_1 x_1 + \dots$

### 3.1 缩放影响分析
令 $y' = y/K$。
$$ \mu' = \mu / K = \frac{1}{K}(\beta_0 + \beta_1 x_1 + \dots) $$
$$ \mu' = \frac{\\beta_0}{K} + \frac{\\beta_1}{K} x_1 + \dots $$

*   **截距 ($\\beta_0$)**: 缩小 $K$ 倍。$\\beta'_0 = \beta_0 / K$。
*   **斜率 ($\\beta_{i>0}$)**: 缩小 $K$ 倍。$\\beta'_i = \beta_i / K$。

### 3.2 实施建议
*   **操作**: 训练前除以 $K$。
*   **恢复**: 预测结果乘以 $K$，或者将模型系数 $\\beta'$ 乘以 $K$ 还原。
*   **正则化警示**:
    *   目标函数通常为 $\frac{1}{2}(y' - X\\beta')^2 + \frac{\\lambda}{2} \|\\beta'\|^2$。
    *   由于 $y$ 缩小了 $K$ 倍，Loss（第一项）大约缩小了 $K^2$ 倍。
    *   如果不调整 $\\lambda$，正则化项的相对权重会变得巨大，导致模型**严重欠拟合 (Underfitting)**，系数被压扁为 0。
    *   **修正**: 理论上应使 $\\lambda' \approx \\lambda / K^2$ 以保持相似的惩罚力度。

---

## 4. 场景三：Logistic Regression (逻辑回归)

**场景**: 二分类 (0/1)、点击率预测 (CTR)。
**模型**: $\ln(\frac{\\mu}{1-\\mu}) = X\\beta \implies \\mu = \frac{1}{1 + e^{-X\\beta}}$

### 4.1 为什么不要缩放？
1.  **标签性质**: Logistic 回归的标签 $y$ 通常是离散的 {0, 1}。
    *   在定点数表示中，0 和 1 是非常安全的数值（例如 0.0 和 1.0），**不存在溢出风险**。
    *   因此，**没有任何工程理由**去缩放它。
2.  **数学破坏**:
    *   Logistic 模型的预测输出 $\\mu$ 是概率，被 Sigmoid 函数严格限制在 (0, 1) 区间内。
    *   如果你强行缩放 $y' = y / 1000$，使得正样本标签变为 0.001。
    *   模型会试图拟合 $\\mu \approx 0.001$。这意味着 $X\\beta$ 必须是非常大的负数 ($\\text{sigmoid}(-6.9) \approx 0.001$)。
    *   这实际上改变了问题的定义：你不再是预测“是/否”，而是在预测“某种极低概率事件的发生率”。这会导致截距项 $\\beta_0$ 变得极小（负无穷方向），且模型对特征的敏感度（梯度）会发生畸变。

### 4.2 唯一例外：聚合数据 (Binomial Regression)
*   如果你的输入不是单条样本 (0/1)，而是聚合数据（例如：某组人中有 $k$ 人购买，总人数 $n$）。
*   此时标签是发生率 $y = k/n$。
*   **处理**: 这个 $y$ 本身已经在 [0, 1] 之间，**不需要额外缩放**。直接使用 Binomial 分布训练即可。

---

## 5. 总结对照表

| 维度 | Log Link (Tweedie/Gamma) | Identity Link (Gaussian) | Logit Link (Bernoulli) |
| :--- | :--- | :--- | :--- |
| **典型场景** | 车险赔款, 销售额 | 房价, 身高 | 欺诈检测, 点击率 |
| **标签范围** | [0, +∞) (可能很大) | (-∞, +∞) | {0, 1} |
| **缩放操作 $y/K$** | **推荐** (若 $y$ 很大) | **可行** | **禁止** |
| **截距变化** | 平移 ($\\beta_0 - \ln K$) | 缩放 ($\\beta_0 / K$) | N/A |
| **斜率变化** | **不变** (Invariant) | 缩放 ($\\beta / K$) | N/A |
| **正则化调整** | 无需大幅调整 | 需减小 ($\\lambda / K^2$) | N/A |
| **恢复方式** | 预测值 $\\times K$ | 预测值 $\\times K$ | N/A |

### 最佳实践 (Best Practices for MPC)
1.  **对于连续值回归 (Gamma/Tweedie/Normal)**: 总是检查 $y$ 的最大值。如果超过定点数安全范围（如 $> 1000$），则进行缩放。
2.  **优先选择 Log Link**: 如果业务允许，优先使用 Log Link 处理正值回归任务。因为它对缩放不敏感，特征系数稳定，调参更简单。
3.  **对于分类任务**: 保持 $y \in$ {0, 1}，不做任何缩放。
